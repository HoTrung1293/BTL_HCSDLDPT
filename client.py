import librosa
import librosa.display
import matplotlib.pyplot as plt
import os
import numpy as np
import pandas as pd
import streamlit as st
from glob import glob
from sklearn.preprocessing import StandardScaler
import joblib
from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity, manhattan_distances
import shutil
import time
import plotly.express as px

st.markdown("""
    <style>
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 8px;
    }
    .stSidebar {
        background-color: #f0f2f6;
    }
    .stSpinner {
        color: #4CAF50;
    }
    h1, h2, h3 {
        color: #333;
    }
    </style>
""", unsafe_allow_html=True)

def extract_audio_features(audio_path):
    try:
        y, sr = librosa.load(audio_path, sr=16000)
        y = librosa.util.fix_length(y, size=5 * sr)

        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        pitch, mag = librosa.piptrack(y=y, sr=sr)
        pitches = pitch[mag > np.median(mag)]
        pitch_mean = np.mean(pitches) if len(pitches) > 0 else 0

        zcr = np.mean(librosa.feature.zero_crossing_rate(y))
        energy = np.mean(y ** 2)
        centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))

        return {
            "mfcc": np.mean(mfcc, axis=1).tolist(),
            "pitch": float(pitch_mean),
            "energy": float(energy),
            "zcr": float(zcr),
            "centroid": float(centroid)
        }
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω file √¢m thanh: {e}")
        return None

def find_nearest_audio(input_audio, features_csv, scaler_path="scaler.pkl", top_k=4, distance_metric="Euclidean"):
    start_time = time.time()
    features = extract_audio_features(input_audio)
    if features is None:
        return [], []

    input_features = [features["pitch"], features["energy"], features["zcr"], features["centroid"]] + features["mfcc"]

    try:
        scaler = joblib.load(scaler_path)
        input_scaled = scaler.transform([input_features])

        df_features = pd.read_csv(features_csv)
        if df_features.empty:
            st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu trong file CSV!")
            return [], input_features

        filenames = df_features["filename"].values
        feature_cols = [col for col in df_features.columns if col != "filename"]
        feature_vectors = df_features[feature_cols].values

        if distance_metric == "Euclidean":
            distances = euclidean_distances(input_scaled, feature_vectors)[0]
        elif distance_metric == "Cosine":
            distances = 1 - cosine_similarity(input_scaled, feature_vectors)[0]
        elif distance_metric == "Manhattan":
            distances = manhattan_distances(input_scaled, feature_vectors)[0]
        else:
            raise ValueError("Unsupported distance metric")

        nearest_indices = np.argsort(distances)[:top_k]
        nearest_files = [(filenames[i], distances[i], feature_vectors[i]) for i in nearest_indices]

        end_time = time.time()
        time_taken = end_time - start_time
        st.success(f"‚úÖ T√¨m th·∫•y {len(nearest_indices)-1} file t∆∞∆°ng gi·ªëng. Th·ªùi gian x·ª≠ l√Ω: {time_taken:.2f} gi√¢y.")

        return nearest_files, input_features
    except Exception as e:
        st.error(f"L·ªói khi t√¨m ki·∫øm file t∆∞∆°ng ƒë·ªìng: {e}")
        return [], input_features

st.title("·ª®ng d·ª•ng T√¨m File √Çm Thanh T∆∞∆°ng ƒê·ªìng")

st.sidebar.subheader("üìê C√†i ƒë·∫∑t")
distance_metric = st.sidebar.selectbox("Thu·∫≠t to√°n ƒëo kho·∫£ng c√°ch", ["Euclidean", "Cosine", "Manhattan"])

with st.sidebar.expander("üß™ C√¥ng th·ª©c c√°c thu·∫≠t to√°n"):
    st.markdown("**Euclidean Distance:**  \n"
                "$$d(p, q) = \\sqrt{\\sum_i (p_i - q_i)^2}$$")
    st.markdown("**Cosine Similarity:**  \n"
                "$$\\cos(\\theta) = \\frac{p \\cdot q}{\\|p\\| \\cdot \\|q\\|}$$")
    st.markdown("**Manhattan Distance:**  \n"
                "$$d(p, q) = \\sum_i |p_i - q_i|$$")

st.sidebar.header("T·∫£i l√™n file √¢m thanh")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn file √¢m thanh", type=["wav"])
if uploaded_file is not None:
    if uploaded_file.size > 10 * 1024 * 1024: 
        st.error("File qu√° l·ªõn! Vui l√≤ng t·∫£i file d∆∞·ªõi 10MB.")
    else:
        with open("input_sample.wav", "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.audio(uploaded_file, format="audio/wav")

        with st.spinner("ƒêang x·ª≠ l√Ω file √¢m thanh..."):
            nearest, input_feats = find_nearest_audio("input_sample.wav", "voice_features_normalized.csv",
                                                     top_k=4, distance_metric=distance_metric)

        if nearest:
            os.makedirs("output", exist_ok=True)
            for filename, dist, _ in nearest:
                output_path = os.path.join("output", filename)
                input_path = os.path.join("data", filename)
                shutil.copy(input_path, output_path)

            st.subheader(f"K·∫øt qu·∫£ t√¨m ki·∫øm ({distance_metric})")
            
            # max_distance = max([dist for _, dist, _ in nearest]) if nearest else 1
            for filename, dist, _ in nearest:
                if filename != uploaded_file.name:
                    # similarity = (1 - dist / max_distance) * 100
                    
                    similarity = (1 / (1 + dist)) * 100  # ƒê·∫£m b·∫£o gi√° tr·ªã n·∫±m trong (0, 100]
  
                    st.write(f"{filename}: ƒê·ªô t∆∞∆°ng ƒë·ªìng {similarity:.2f}%")
                    st.audio(os.path.join("output", filename), format="audio/wav")

            st.subheader("Waveform")
            st.write("Bi·ªÉu ƒë·ªì hi·ªÉn th·ªã bi√™n ƒë·ªô √¢m thanh theo th·ªùi gian.")
            y_input, sr_input = librosa.load("input_sample.wav", sr=16000)
            fig, axes = plt.subplots(1,len(nearest), figsize=(20, 4))

            if len(nearest) == 0:
                axes = [axes]
            else:
                axes = axes.flatten()

            librosa.display.waveshow(y_input, sr=sr_input, ax=axes[0])
            axes[0].set_title("Waveform c·ªßa Input Audio")
            axes[0].set_xlabel("Th·ªùi gian (s)")
            axes[0].set_ylabel("Bi√™n ƒë·ªô")

            output_files = []
            for filename, _, _ in nearest:
                if filename != uploaded_file.name:
                    output_files.append(os.path.join("output", filename))      
                    
            # output_files = [os.path.join("output", filename) for filename, _, _ in nearest]
            # print(output_files)
            for i, output_file in enumerate(output_files):
               
                    y_output, sr_output = librosa.load(output_file, sr=16000)
                    librosa.display.waveshow(y_output, sr=sr_output, ax=axes[i + 1])
                    axes[i + 1].set_title(f"Waveform c·ªßa Output {i + 1}")
                    axes[i + 1].set_xlabel("Th·ªùi gian (s)")
                    axes[i + 1].set_ylabel("Bi√™n ƒë·ªô")

            plt.tight_layout()
            st.pyplot(fig)
            st.subheader("MFCC")
            st.write("Bi·ªÉu ƒë·ªì hi·ªÉn th·ªã c√°c h·ªá s·ªë MFCC, bi·ªÉu th·ªã ƒë·∫∑c tr∆∞ng √¢m s·∫Øc.")
            mfcc_input = librosa.feature.mfcc(y=y_input, sr=sr_input, n_mfcc=13)
            fig, axes = plt.subplots(1, len(nearest), figsize=(20, 4))

            if len(nearest) == 0:
                axes = [axes]
            else:
                axes = axes.flatten()

            librosa.display.specshow(mfcc_input, x_axis='time', sr=sr_input, ax=axes[0])
            axes[0].set_title("MFCC c·ªßa Input Audio")
            axes[0].set_xlabel("Th·ªùi gian (s)")
            axes[0].set_ylabel("MFCC Coefficients")

            for i, output_file in enumerate(output_files):
               
                    y_output, sr_output = librosa.load(output_file, sr=16000)
                    mfcc_output = librosa.feature.mfcc(y=y_output, sr=sr_output, n_mfcc=13)
                    librosa.display.specshow(mfcc_output, x_axis='time', sr=sr_output, ax=axes[i + 1])
                    axes[i + 1].set_title(f"MFCC c·ªßa Output {i + 1}")
                    axes[i + 1].set_xlabel("Th·ªùi gian (s)")
                    axes[i + 1].set_ylabel("MFCC Coefficients")

            plt.tight_layout()
            st.pyplot(fig)

            st.subheader("Spectrogram")
            st.write("Bi·ªÉu ƒë·ªì hi·ªÉn th·ªã ph·ªï t·∫ßn s·ªë theo th·ªùi gian.")
            D_input = librosa.amplitude_to_db(librosa.stft(y_input), ref=np.max)
            fig, axes = plt.subplots(1, len(nearest), figsize=(20, 4))

            if len(nearest) == 0:
                axes = [axes]
            else:
                axes = axes.flatten()

            librosa.display.specshow(D_input, x_axis='time', y_axis='log', sr=sr_input, ax=axes[0])
            axes[0].set_title("Spectrogram c·ªßa Input Audio")
            axes[0].set_xlabel("Th·ªùi gian (s)")
            axes[0].set_ylabel("T·∫ßn s·ªë (Hz)")

            for i, output_file in enumerate(output_files):
                    y_output, sr_output = librosa.load(output_file, sr=16000)
                    D_output = librosa.amplitude_to_db(librosa.stft(y_output), ref=np.max)
                    librosa.display.specshow(D_output, x_axis='time', y_axis='log', sr=sr_output, ax=axes[i + 1])
                    axes[i + 1].set_title(f"Spectrogram c·ªßa Output {i + 1}")
                    axes[i + 1].set_xlabel("Th·ªùi gian (s)")
                    axes[i + 1].set_ylabel("T·∫ßn s·ªë (Hz)")

            plt.tight_layout()
            st.pyplot(fig)

            feature_names = ["pitch", "energy", "zcr", "centroid"] + [f"mfcc_{i}" for i in range(13)]
            df_compare = pd.DataFrame(columns=["file", "distance"] + feature_names)

            input_row = ["Input", 0.0] + input_feats
            df_compare.loc[0] = input_row

            for idx, (fname, dist, feats) in enumerate(nearest):
                row = [fname, round(dist, 4)] + list(feats)
                df_compare.loc[idx + 1] = row

            st.subheader(f"So s√°nh ƒë·∫∑c tr∆∞ng ({distance_metric})")
            st.dataframe(df_compare, use_container_width=True)

            st.subheader("Bi·ªÉu ƒë·ªì so s√°nh ƒë·∫∑c tr∆∞ng")
            selected_features = st.multiselect("Ch·ªçn ƒë·∫∑c tr∆∞ng ƒë·ªÉ so s√°nh", feature_names, default=["pitch", "energy", "zcr", "centroid"])
            if selected_features:
                fig = px.bar(df_compare, x="file", y=selected_features, barmode="group", title="So s√°nh ƒë·∫∑c tr∆∞ng")
                st.plotly_chart(fig)

            csv = df_compare.to_csv(index=False)
            st.download_button("T·∫£i b·∫£ng so s√°nh", csv, "comparison.csv", "text/csv")
